# -*- coding: utf-8 -*-
"""CNN-MNIST.ipynb

Automatically generated by Colaboratory.
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
# %matplotlib inline

import tensorflow
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, Flatten
from tensorflow.keras.datasets import mnist

(X_train, y_train),(X_test,y_test) = mnist.load_data()

X_train.shape

first_image = X_train[0]
first_image

plt.figure(figsize=(3,3))
plt.imshow(first_image)

print(y_train.shape)
y_train

"""one hot encoding the labels (y_train and y_test)"""

from tensorflow.keras.utils import to_categorical

y_train_cat = to_categorical(y_train, num_classes = 10)
print(y_train.shape)

y_test_cat = to_categorical(y_test, num_classes = 10)
print(y_test.shape)

y_train_cat[0]

"""Scaling the input features (X_train and X_test)"""

X_train = X_train/255
X_test = X_test/255

X_train[0]   # all the values are scaled in the range (0,1)

# batch_size, width, height, color_channels
X_train = X_train.reshape(60000, 28,28,1)

X_test = X_test.reshape(10000,28,28,1)

"""Creating the cnn model"""

model = Sequential()

model.add(Conv2D(filters=32, kernel_size=(3,3), strides=(1,1), padding='same', input_shape=(28,28,1), activation='relu'))
model.add(MaxPool2D(pool_size=(2,2)))

model.add(Conv2D(filters=32, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu'))
model.add(MaxPool2D(pool_size=(2,2)))

model.add(Flatten())

model.add(Dense(128, activation='relu'))

# output layer
model.add(Dense(10, activation='softmax'))

model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

"""Adding early stopping"""

from tensorflow.keras.callbacks import EarlyStopping

early_stop = EarlyStopping(monitor='val_loss',patience=1,verbose=1)

"""Training the model"""

model.fit(X_train, y_train_cat, epochs=10, validation_data=(X_test,y_test_cat),callbacks=early_stop)

"""Getting the metrics"""

metrics = pd.DataFrame(model.history.history)

metrics

metrics[['loss','val_loss']].plot()
# we stopped training the model as the validation loss started to increase means the model started to overfit

metrics[['accuracy','val_accuracy']].plot()

from sklearn.metrics import classification_report, confusion_matrix

y_test

predictions = model.predict(X_test)

preds = np.argmax(predictions, axis=1)

print(classification_report(y_test,preds))

confusion_matrix(y_test,preds)

"""Prediction"""

number = X_test[0]
plt.imshow(number)

number.shape

# num_images,width,height,color_channels
np.argmax(model.predict(number.reshape(1,28,28,1)),axis=1)
